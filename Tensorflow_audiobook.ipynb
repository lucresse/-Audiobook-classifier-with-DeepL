{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_audiobook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cstL8D9GfQyS",
        "colab_type": "text"
      },
      "source": [
        "## Audiobook classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-ThgGt3r7g4",
        "colab_type": "text"
      },
      "source": [
        "## Problem\n",
        "\n",
        "You are given data from an Audiobook app. Logically, it relates only to the audio versions of books. Each customer in the database has made a purchase at least once, that's why he/she is in the database. We want to create a machine learning algorithm based on our available data that can predict if a customer will buy again from the Audiobook company.\n",
        "\n",
        "The main idea is that if a customer has a low probability of coming back, there is no reason to spend any money on advertizing to him/her. If we can focus our efforts ONLY on customers that are likely to convert again, we can make great savings. Moreover, this model can identify the most important metrics for a customer to come back again. Identifying new customers creates value and growth opportunities.\n",
        "\n",
        "You have a .csv summarizing the data. There are several variables: Customer ID, Book length in mins_avg (average of all purchases), Book length in minutes_sum (sum of all purchases), Price Paid_avg (average of all purchases), Price paid_sum (sum of all purchases), Review (a Boolean variable), Review (out of 10), Total minutes listened, Completion (from 0 to 1), Support requests (number), and Last visited minus purchase date (in days).\n",
        "\n",
        "So these are the inputs (excluding customer ID, as it is completely arbitrary. It's more like a name, than a number).\n",
        "\n",
        "The targets are a Boolean variable (so 0, or 1). We are taking a period of 2 years in our inputs, and the next 6 months as targets. So, in fact, we are predicting if: based on the last 2 years of activity and engagement, a customer will convert in the next 6 months. 6 months sounds like a reasonable time. If they don't convert after 6 months, chances are they've gone to a competitor or didn't like the Audiobook way of digesting information. \n",
        "\n",
        "The task is simple: create a machine learning algorithm, which is able to predict if a customer will buy again. \n",
        "\n",
        "This is a classification problem with two classes: won't buy and will buy, represented by 0s and 1s. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOKZ5z917b6Z",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCU4P7_vfQyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's preprocess the data\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "raw_data = np.loadtxt('Audiobooks_data.csv', delimiter=',')\n",
        "\n",
        "# To extract inputs and targets\n",
        "inputs_all = raw_data[:,1:-1]\n",
        "target_all = raw_data[:,-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tFKj0tgnIZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8df378a1-9b26-4ef9-9ba8-c526dd81598e"
      },
      "source": [
        "target_all.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14084"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3sgysjktZqb",
        "colab_type": "text"
      },
      "source": [
        "### To visualize the number of 1 and the number of 0 in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3apgbGwshXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b3581247-0beb-4402-a92f-0c431c3588e4"
      },
      "source": [
        "data_panda = pd.DataFrame(raw_data)\n",
        "data_panda.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>873.0</td>\n",
              "      <td>2160.0</td>\n",
              "      <td>2160.0</td>\n",
              "      <td>10.13</td>\n",
              "      <td>10.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>611.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>2808.0</td>\n",
              "      <td>6.66</td>\n",
              "      <td>13.33</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>705.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>10.13</td>\n",
              "      <td>10.13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>334.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>391.0</td>\n",
              "      <td>1620.0</td>\n",
              "      <td>1620.0</td>\n",
              "      <td>15.31</td>\n",
              "      <td>15.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>819.0</td>\n",
              "      <td>432.0</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>7.11</td>\n",
              "      <td>21.33</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0       1       2      3      4    5     6    7    8    9     10   11\n",
              "0  873.0  2160.0  2160.0  10.13  10.13  0.0  8.91  0.0  0.0  0.0    0.0  1.0\n",
              "1  611.0  1404.0  2808.0   6.66  13.33  1.0  6.50  0.0  0.0  0.0  182.0  1.0\n",
              "2  705.0   324.0   324.0  10.13  10.13  1.0  9.00  0.0  0.0  1.0  334.0  1.0\n",
              "3  391.0  1620.0  1620.0  15.31  15.31  0.0  9.00  0.0  0.0  0.0  183.0  1.0\n",
              "4  819.0   432.0  1296.0   7.11  21.33  1.0  9.00  0.0  0.0  0.0    0.0  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USe3BV9ht8K-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ec6b9e0-fc57-429b-f0d6-d937004a8588"
      },
      "source": [
        "one = np.sum(raw_data[:,-1])\n",
        "print('number of one are {} and the number of zeros are {}'.format(one, len(data_panda)-one))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of one are 2237.0 and the number of zeros are 11847.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EcY0uJpvRBl",
        "colab_type": "text"
      },
      "source": [
        "#### We can see that the data is imbalanced. So, we need to balance the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW81QTg2vd8U",
        "colab_type": "text"
      },
      "source": [
        "## Balanced the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ual7DA-TfQyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8705d07-74cd-4eb0-f832-8d9b4749aecd"
      },
      "source": [
        "# We need to balance the data\n",
        "num_one_target = int(np.sum(target_all))\n",
        "target_zero_counter = 0\n",
        "indice_to_remove = []\n",
        "\n",
        "for i in range(target_all.shape[0]):\n",
        "  if target_all[i] == 0:\n",
        "    target_zero_counter +=1\n",
        "    if target_zero_counter > num_one_target:\n",
        "      indice_to_remove.append(i)\n",
        "\n",
        "inputs_all = np.delete(inputs_all, indice_to_remove, axis=0)\n",
        "target_all = np.delete(target_all, indice_to_remove, axis=0)\n",
        "target_all.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4474,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7YagJcAfQyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d45fd76-8724-4296-9d51-d2c82b928feb"
      },
      "source": [
        "# Let's standardize the data\n",
        "scale_inputs = preprocessing.scale(inputs_all)\n",
        "scale_inputs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4474, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg-CwwwS0H7l",
        "colab_type": "text"
      },
      "source": [
        "## Shuffle the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ5UqorA0Rf8",
        "colab_type": "text"
      },
      "source": [
        "##### When the data was collected it was actually arranged by date. Shuffle the indices of the data, so the data is not arranged in any way when we feed it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA834LfpfQyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's shuffle the data\n",
        "\n",
        "shuffle_indice = np.arange(scale_inputs.shape[0])\n",
        "np.random.shuffle(shuffle_indice)\n",
        "\n",
        "# let's use the shuffle_indice to shuffle the inputs and targets\n",
        "shuffle_inputs = scale_inputs[shuffle_indice]\n",
        "shuffle_targets = target_all[shuffle_indice]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lVI2oWlt--v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "65bd7bfd-87d5-4c57-9f09-afc1e8fa1230"
      },
      "source": [
        "# Let's split the data into train, validation, test\n",
        "samples_count = shuffle_inputs.shape[0]\n",
        "\n",
        "# Count the samples in each subset, assuming we want 80-10-10 distribution of training, validation, and test.\n",
        "# Naturally, the numbers are integers.\n",
        "train_sample_count = int(0.8*samples_count)\n",
        "validation_sample_count = int(0.1*samples_count)\n",
        "\n",
        "# Create variables that record the inputs and targets for training\n",
        "# In our shuffled dataset, they are the first \"train_samples_count\" observations\n",
        "train_inputs = shuffle_inputs[:train_sample_count]\n",
        "target_inputs = shuffle_targets[:train_sample_count]\n",
        "\n",
        "# Create variables that record the inputs and targets for validation.\n",
        "# They are the next \"validation_samples_count\" observations, folllowing the \"train_samples_count\" we already assigned\n",
        "validation_inputs = shuffle_inputs[train_sample_count:train_sample_count+validation_sample_count]\n",
        "validation_target = shuffle_targets[train_sample_count:train_sample_count+validation_sample_count]\n",
        "\n",
        "# The 'test' dataset contains all remaining data.\n",
        "test_sample_count = samples_count - train_sample_count - validation_sample_count\n",
        "\n",
        "# Create variables that record the inputs and targets for test.\n",
        "# They are everything that is remaining.\n",
        "test_inputs = shuffle_inputs[train_sample_count+validation_sample_count:]\n",
        "test_targets = shuffle_targets[train_sample_count+validation_sample_count:]\n",
        "\n",
        "\n",
        "# We balanced our dataset to be 50-50 (for targets 0 and 1), but the training, validation, and test were \n",
        "# taken from a shuffled dataset. Check if they are balanced, too. \n",
        "\n",
        "# Print the number of targets that are 1s, the total number of samples, and the proportion for training, validation, and test.\n",
        "print(np.sum(target_inputs), train_sample_count, np.sum(target_inputs)/train_sample_count)\n",
        "print(np.sum(validation_target), validation_sample_count, np.sum(validation_target)/validation_sample_count)\n",
        "print(np.sum(test_targets), test_sample_count, np.sum(test_targets)/test_sample_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1821.0 3579 0.5088013411567477\n",
            "193.0 447 0.4317673378076063\n",
            "223.0 448 0.49776785714285715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxBH71Yi2cwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e2e496a-0a38-43eb-a322-c9471d4e6e72"
      },
      "source": [
        "3579+447+448"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtjyWnul0fFi",
        "colab_type": "text"
      },
      "source": [
        "## Save the three datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaVCr50g396l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's save the three datasets in *.npz.\n",
        "np.savez('Audiobooks_data_train', inputs=train_inputs, targets = target_inputs)\n",
        "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets = validation_target)\n",
        "np.savez('Audiobooks_data_test', inputs=test_inputs, targets = test_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TinuwgAu60ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag-98CcS7iLh",
        "colab_type": "text"
      },
      "source": [
        "## Create the Machine learning algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufk_DxQIrU0g",
        "colab_type": "text"
      },
      "source": [
        "Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpXNlgLL7ozo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's create a temporary variable npz\n",
        "npz = np.load('Audiobooks_data_train.npz')\n",
        "# inputs must be float\n",
        "train_inputs = npz['inputs'].astype(np.float)\n",
        "# targets must be integer\n",
        "target_inputs = npz['targets'].astype(np.int)\n",
        "\n",
        "# Do the same thing for validation and test set\n",
        "npz = np.load('Audiobooks_data_validation.npz')\n",
        "validation_inputs, validation_target = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
        "\n",
        "npz = np.load('Audiobooks_data_test.npz')\n",
        "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11ldp1ohAkwm",
        "colab_type": "text"
      },
      "source": [
        "### Let's build our Model here\n",
        "Outline, optimizers, loss, early stopping and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN5sPjx7AV71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "bf7cfbaa-052b-4c64-cf76-24a94f5ec7c3"
      },
      "source": [
        "input_size = 10\n",
        "output_size = 2\n",
        "\n",
        "hidden_layer_size = 50\n",
        "\n",
        "model_audio = tf.keras.Sequential([\n",
        "                  tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
        "                  tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
        "                  #tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'), \n",
        "\n",
        "                  tf.keras.layers.Dense(output_size, activation = 'softmax'),\n",
        "])\n",
        "\n",
        "bacth_size = 100\n",
        "num_epochs = 100\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
        "\n",
        "model_audio.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#print(validation_inputs.shape)\n",
        "#print(validation_target.shape)\n",
        "model_audio.fit(\n",
        "    train_inputs,\n",
        "    target_inputs,\n",
        "    bacth_size = bacth_size,\n",
        "    epochs = num_epochs,\n",
        "    validation_data = (validation_inputs, validation_target),\n",
        "    callbacks = [early_stopping],\n",
        "    verbose = 2\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "112/112 - 0s - loss: 0.4299 - accuracy: 0.8326 - val_loss: 0.3099 - val_accuracy: 0.8747\n",
            "Epoch 2/100\n",
            "112/112 - 0s - loss: 0.2972 - accuracy: 0.8908 - val_loss: 0.2897 - val_accuracy: 0.8792\n",
            "Epoch 3/100\n",
            "112/112 - 0s - loss: 0.2714 - accuracy: 0.8972 - val_loss: 0.2835 - val_accuracy: 0.8792\n",
            "Epoch 4/100\n",
            "112/112 - 0s - loss: 0.2633 - accuracy: 0.9019 - val_loss: 0.2619 - val_accuracy: 0.8837\n",
            "Epoch 5/100\n",
            "112/112 - 0s - loss: 0.2552 - accuracy: 0.9044 - val_loss: 0.2692 - val_accuracy: 0.8837\n",
            "Epoch 6/100\n",
            "112/112 - 0s - loss: 0.2491 - accuracy: 0.9078 - val_loss: 0.2853 - val_accuracy: 0.8837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6cd287ba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ohWvGTOG5sB",
        "colab_type": "text"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oNox5BwKzqH",
        "colab_type": "text"
      },
      "source": [
        "##### The model has to be test with unseen data. This help us to know at what level our model is able to do a good classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psYaPYx2G28n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9ad7db25-72ce-45cc-f012-f0413b81dac1"
      },
      "source": [
        "test_loss, test_accuracy = model_audio.evaluate(test_inputs, test_targets)\n",
        "\n",
        "print('test_loss: {0:.2f}. test_accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n",
        "\n",
        "# the accuracy should be around 90%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9107\n",
            "test_loss: 0.24. test_accuracy: 91.07%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZKQKoC4Jr5A",
        "colab_type": "text"
      },
      "source": [
        "#### The test_accuracy below shows that our model is good at 91%. It means that for any new data the model can classify it with an uncertainty of 9%.\n",
        "##### Note that when we rerun the model, the accuracy value must change because of some randomness included in our model. The challenge now is to some good hyperparameters that can gives the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkSNpnCvNgE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}